# Обусловленность и устойчивость

### Обусловленность задачи

Пусть есть абстрактная вычислительная задача. 

Дано: $x$, найти: $f(x)$. Коль скоро $x$ – это нечто, представленное в компьютере, можно сказать, что он представлен неточно, отличается от истинного на некоторое значение $\Delta x$. Часто бывает так, что и сами исходные данные представлены с какой-то ошибкой.

<img src=".\sources\LETI7\deltaf.png" alt="deltaf" style="zoom:25%;" />

Необходимо исследовать, как такие ошибки влияют на значения функции $f(x)$.

*Абсолютная обусловленность* это предел отношения нормы приращения $f$ к норме приращения $x$:

<img src=".\sources\LETI7\nu.png" alt="nu" style="zoom:25%;" />

Более естественным понятием является *относительная обусловленность*:

<img src=".\sources\LETI7\mu.png" alt="mu" style="zoom:25%;" />

Допустим, если $\mu = 10$, можно сказать, что одна неизвестная десятичная цифра в $x$ приводит к тому, что в $f$ неизвестно уже две десятичные цифры.

#### Обусловленность задачи вычисления значения вещественной функции одной переменной

В случае такой задачи вычисления обусловленности несколько упрощаются:

* Абсолютная обусловленность – <img src=".\sources\LETI7\nufprime.png" alt="nufprime" style="zoom:25%;" />
* Относительная обусловленность – <img src=".\sources\LETI7\mufprime.png" alt="mufprime" style="zoom:25%;" />

Рассмотрим значения относительной обусловленности для некоторых функций:

<img src=".\sources\LETI7\mus.png" alt="mus" style="zoom:25%;" />

Задача вычисления корня обусловлена хорошо, что можно сказать и про $f(x)=\dfrac{1}{x}$.

Задача вычисления $f(x)=e^x$ при больших значениях $x$ обусловлена плохо.

График относительной обусловленности задачи вычисления функции $f(x)=\sin x$ представлен ниже:

<img src=".\sources\LETI7\xtan.png" alt="xtan" style="zoom: 50%;" />

Наиболее хорошая обусловленность в промежутке $[-\pi/2, \pi/2]$

Не все функции имеют удобную относительную обусловленность, например $f(x)=\log x$:

<img src=".\sources\LETI7\logx.png" alt="logx" style="zoom:25%;" />

Несложно заметить, что в районе 1 число относительной обусловленности стремится к бесконечности.

В проектировании машинных алгоритмов, однако, вышеописанные соображения по поводу обусловленности не играют большой роли, потому что в компьютере нет бесконечно малых величин, а есть дискретная сетка чисел. Необходимо обеспечить верность значащих битов вычисляемой функции. Эта цель достигается средствами, порой не связанными (по крайней мере напрямую) с обусловленностью.

### Погрешности машинной арифметики

Отметим несколько аспектов того, как организуются вычисления в машинной арифметики. Прежде всего, определим погрешность представления:

<img src=".\sources\LETI7\deltaxy.png" alt="deltaxy" style="zoom:25%;" />

Предположим, необходимо посчитать $x^2-y^2$. Вычислим погрешности операций, если сначала возводить $x$ в квадрат, затем $y$ в квадрат, а затем производить вычитание:

$x \otimes x = (x \times x)(1 + \delta_1), |\delta_1| \le \epsilon$

$y \otimes y = (y \times y)(1 + \delta_2), |\delta_2| \le \epsilon$

$(x \otimes x) \ominus(y \otimes y) = (x^2(1+\delta_1) - y^2(1+\delta_2))(1+\delta_3), |\delta_3| \le \epsilon$

И теперь можно определить относительную погрешность представления всего выражения:

<img src=".\sources\LETI7\relerr-2.png" alt="relerr-2" style="zoom:25%;" />

Можно сказать, что алгоритм неустойчивый, так как относительная погрешность зависит от значений $x,y$.

Теперь вычислим то же выражение, но использовав разложение $x^2-y^2=(x+y)(x-y)$:

<img src=".\sources\LETI7\relerr-3.png" alt="relerr-3" style="zoom:25%;" />

Алгоритм можно считать устойчивым.

Фактически была решена одна и та же задача, но разными методами. Поэтому стоит говорить не только об обусловленности задачи, но и об обусловленности методов: иногда задача может быть хорошо обусловлена, а метод может оказаться неустойчивым.

#### Обусловленность задачи нахождения корня функции

Дано: $f(x)=0$. Найти: $x$.

Задача поменялась – теперь дана функция $f(x)$, а найти необходимо $x$, таким образом в определении числа обусловленности меняются местами числитель и знаменатель. Относительная обусловленность:

<img src=".\sources\LETI7\mu-root.png" alt="mu-root" style="zoom:25%;" />

В окрестности точки, где $f'=0$, численный метод, использующий $f$ для нахождения корня, скорее всего, не сойдется из-за плохой обусловленности задачи.

Теперь рассмотрим обусловленность задачи нахождения корня многочлена.

Дано: <img src=".\sources\LETI7\px.png" alt="px" style="zoom:25%;" />. Найти: $x$

Выпишем следующую частную производную, что позволит определить относительную обусловленность:

<img src=".\sources\LETI7\dxdak.png" alt="dxdak" style="zoom:25%;" />

Можно показать, что чувствительность будет высокая в тех точках, где производная многочлена равна 0, то есть решение нестабильно для кратных корней.

Кратность корня – не единственная причина, по которой обусловленность задачи может быть плохой.

Известен многочлен Уилкинсона:

<img src=".\sources\LETI7\wx.png" alt="wx" style="zoom:25%;" />

График многочлена:

<img src=".\sources\LETI7\wilk.png" alt="wilk" style="zoom:50%;" />

Экспериментально было показано, что многочлен очень чувствителен к малейшим изменениям коэффициента – изменение коэффициента на маленькое значение может повлечь за собой изменение корня на большие значения.

Чувствительность к коэффициентам полиномов, получающихся в результате интерполяции, как правило, также высока.

#### Решение квадратного уравнения

Дано: $ax^2+bx+c=0$. Найти: $x$.

Решение общеизвестно:

<img src=".\sources\LETI7\x-quad.png" alt="x-quad" style="zoom:25%;" />

Итак, число относительной обусловленности системы при параметрах $a, b, c$ (в каждом случае два остальных параметра считаются фиксированными):

<img src=".\sources\LETI7\muabc.png" alt="muabc" style="zoom:25%;" />

При кратных корнях, то есть при $D=0$, то получаем стремящееся к бесконечности число относительной обусловленности, что означает нестабильную работу данной формулы в случае кратных корней.

Если $a, c$ очень малы, то в числителе для одного из корней получается практически $-b + b$. Получаем катастрофическое сокращение значащих битов, то есть большая часть битов обнулится, что приводит к большой неустойчивости данного численного метода. Чтобы избавиться от этого, несколько изменим формулы для вычисления корней:

Решение для $D \approx b^2$:

<img src=".\sources\LETI7\roots.png" alt="roots" style="zoom:25%;" />

Таким образом, в знаменателе не вычитаются близкие величины, значащие биты не теряются. Ответ получается с меньшей ошибкой. Для второго корня можно использовать теорему Виета. Кроме того, даже если $a=0$, один из корней также можно будет найти.

### Обусловленность СЛАУ

Дано: $A \mathbf{x = b}$. Найти $\mathbf{x}$.

В данной задаче тема обусловленности наиболее актуальна. 

Прежде чем приступать к методам, рассмотрим математическую обусловленность задачи:

<img src=".\sources\LETI7\adeltaa.png" alt="adeltaa" style="zoom:25%;" />

Подробный вывод опустим и выпишем сразу результат:
$$
\Delta A \Delta b \approx 0 \Rightarrow \dfrac{||\Delta \mathbf{x}||}{||\mathbf{x}||} \le \mu\left(\dfrac{||\Delta A||}{||A||} + \dfrac{||\Delta b||}{||b||}\right), \mu=||A|| \cdot ||A^{-1}|| \ge 1
$$
В любом случае, число обусловленности не может быть меньше 1. Числа обусловленности, исчисляемые тысячами, говорят о плохой обусловленности.

Если матрица $A$ симметричная положительно определенная, то число обусловленности – отношение максимального и минимального собственного числа:

<img src=".\sources\LETI7\mu-lambda.png" alt="mu-lambda" style="zoom:25%;" />

#### Пример

Рассмотрим пример того, как работает обусловленность в СЛАУ.

<img src=".\sources\LETI7\cond-1.png" alt="cond-1" style="zoom:25%;" />

Как видно, $x=2, y=0$ подходят как математическое решение системы.

Внесем возмущение в вектор $b$:

<img src=".\sources\LETI7\cond-2.png" alt="cond-2" style="zoom:25%;" />

Решение системы: $x=1, y=1$. Получается совершенно другое решение, несмотря на небольшое возмущение во входных данных. Данная система плохо обусловлена.

Докажем это, посчитав матрицу $A^{-1}$ и вычислив число обусловленности:

<img src=".\sources\LETI7\invmatr.png" alt="invmatr" style="zoom:25%;" />

<img src=".\sources\LETI7\a2.png" alt="a2" style="zoom:25%;" />

Число обусловленности велико, что доказывает плохую обусловленность.

#### Пример №2

В этом примере будет матрица $A$, которая дает вполне приемлемое число обусловленности:

<img src=".\sources\LETI7\ex2.png" alt="ex2" style="zoom:25%;" />

Проведем решение СЛАУ методом Гаусса:

Первым и единственным шагом будут преобразования для приведения матрицы к верхней треугольной, с которой обусловленность уже будет плохой.

![umatr](D:\Github\Dynamic-systems-modeling-course\sources\LETI7\umatr.png)

Таким образом, применение численного метода ведет к плохой обусловленности матрицы, которая изначально не давала плохую обусловленность.

Если воспользоваться методом $LUP$ разложения, то такой проблемы возникать уже не будет (будет выбираться ведущий элемент в столбце, осуществляться перестановка, что исправит ситуацию):

<img src=".\sources\LETI7\pa.png" alt="pa" style="zoom:25%;" />

Таким образом, выбор ведущего элемента влияет на обусловленность. 

Это не является строгим доказательством того, что $LUP$ разложение всегда лучше справляется с возрастанием обусловленности, но на практике чаще всего это так.

Итак, методы могут ухудшать обусловленность матрицы, не менять ее, но могут ли улучшать?

### Предобуславливатели СЛАУ

Модифицируем систему, умножив слева и справа на некоторую (невырожденную) матрицу:

<img src=".\sources\LETI7\precond1.png" alt="precond1" style="zoom:25%;" />

Если обеспечится условие меньшего значения числа обусловленность, то цель достигнута. Вопрос только в том, что это за матрица $M$.

$LUP$-разложение также в некотором роде содержит предобуславливатель, в качестве него выступает матрица $P$:

<img src=".\sources\LETI7\palu.png" alt="palu" style="zoom:25%;" />

Однако для нахождения $P$ требуется прогонка метода, чего хотелось бы избежать.

Чисто формально единичная матрица является предобуславливателем, потому что неравенство чисел обусловленности нестрогое.

<img src=".\sources\LETI7\me.png" alt="me" style="zoom:25%;" />

Также предобуславливателем может быть и сама матрица $A$, ведь тогда число обусловленности станет равно 1:

<img src=".\sources\LETI7\ma.png" alt="ma" style="zoom:25%;" />

Но в таком случае необходимо считать матрицу $A^{-1}$. Вычисление обратной матрицы, во-первых, требует больших затрат, чем нахождение более простого предобуславливателя, и во-вторых, обессмысливает задачу, т. к. сама по себе обратная матрица будет содержать те самые численные ошибки, от которых мы хотели избавиться, вводя предобуславливатель.

Надо понимать, что поиск предобуславливателя – не совсем точная наука, и матрицы $A$ бывают самые разные. Но вот некоторые из них, которые применяются в итеративных методах:

* Предобуславливатель Якоби: <img src=".\sources\LETI7\jacobi.png" alt="jacobi" style="zoom:25%;" />
* Предобуславливатель Гаусса-Зейделя (GS): <img src=".\sources\LETI7\mld.png" alt="mld" style="zoom:25%;" />

* Симметричный предобуславливатель Гаусса-Зейделя (SGS): <img src=".\sources\LETI7\sgs.png" alt="sgs" style="zoom:25%;" />

* Прочие:  SSOR, ILU(0), ILU(n), AMG