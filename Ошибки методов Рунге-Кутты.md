# Ошибки методов Рунге-Кутты

Рассмотрим один из методов Рунге-Кутты.

### Общий явный метод Рунге-Кутты 2-го порядка

Таблица Бутчера для метода:
$$
\begin{array}{|ccc}
     0 & \\
     \alpha & 0 \\
    \hline
     b_1 & b_2
  \end{array}
$$
Коэффициенты рассчитываются следующим образом:
$$
\begin{array}{lcl}
\mathbf{k}_1 &=& \mathbf{f}(\mathbf{x}(t)) \\
\mathbf{k}_2 &=& \mathbf{f}(\mathbf{x}(t) + h \alpha \mathbf{k}_1) 
\end{array}
$$
В методе средней точки, который является частным случаем общего метода, $\alpha = 1/2$.

Формула для $\mathbf{x}(t+h)$:

$\mathbf{x}(t+h) = \mathbf{x}(t) + h(b_1 \mathbf{k}_1 + b_2 \mathbf{k}_2) + O(h^3)$										(1)

Используем разложение в ряд Тейлора для коэффициентов:
$$
\begin{array}{lcl}
\mathbf{k}_1 &=& \mathbf{f} \\
\mathbf{k}_2 &=& \mathbf{f} + h \alpha \mathbf{f}' \mathbf{f} + O(h^2)
\end{array}
$$
Также разложим в ряд Тейлора $\mathbf{x}(t+h)$:

$\begin{array}{lcl}
\mathbf{x}(t+h) &=& \mathbf{x} + h\mathbf{\dot{x}} + \frac{h^2}{2}\mathbf{\ddot{x}} + O(h^3) \\
                &=& \mathbf{x} + h\mathbf{f} + \frac{h^2}{2}\mathbf{f}'\mathbf{f} + O(h^3)
\end{array}$                 											(2)

Приравнивая (1) и (2), составим СЛАУ с неизвестными $b_1, b_2$
$$
\begin{cases}
      b_1 + b_2 = 1\\
      b_2 \alpha = 1/2
    \end{cases}\
$$
Решение этой системы уравнений:
$$
\begin{array}{lcl}
b_1 &=& 1 - \frac{1}{2\alpha}\\
b_2 &=& \frac{1}{2\alpha}
\end{array}
$$
Таким образом, явных методов Рунге-Кутты 2-го порядка может быть бесконечно много, и их многообразие определяется различным выбором значения $\alpha$.

Таблицу Бутчера в таком случае можно записать, используя только $\alpha$:
$$
\begin{array}{|ccc}
     0 & \\
     \alpha & 0 \\
    \hline
     1 - \frac{1}{2\alpha} & \frac{1}{2\alpha}
  \end{array}
$$

#### Примеры

$\alpha = 1 : \  \begin{array}{|ccc}
     0 & \\
     1 & 0 \\
    \hline
     1/2 & 1/2
  \end{array}$ – Метод Хойна

$\alpha = \frac{1}{2}\ : \  \begin{array}{|ccc}
     0 & \\
     1/2 & 0 \\
    \hline
     0 & 1
  \end{array}$ – Метод средней точки

#### Оценка ошибки

Используем разложение в ряд Тейлора для коэффициентов $\mathbf{k_1}, \mathbf{k_2}$ до второго члена ряда:
$$
\begin{array}{lcl}
\mathbf{k}_1 &=& \mathbf{f} \\
\mathbf{k}_2 &=& \mathbf{f} + h \alpha \mathbf{f}' \mathbf{f} + \frac{h^2 \alpha^2}{2} \mathbf{f}''\mathbf{f}\,\mathbf{f} + O(h^3)
\end{array}
$$
С учетом таких разложений коэффициентов запишем уравнение для $\mathbf{x}(t+h)$:

$\mathbf{x}(t+h) = \mathbf{x}(t) + h\mathbf{f} + \frac{h^2}{2}\mathbf{f}'\mathbf{f} + \frac{h^3\alpha}{4}\mathbf{f}''\mathbf{f}\,\mathbf{f} + O(h^4)$									(3)

Сопоставим полученное уравнение с разложением в ряд Тейлора до 3-го члена:

$\begin{array}{lcl}
\mathbf{x}(t+h) &=& \mathbf{x} + h\mathbf{\dot{x}} + \frac{h^2}{2}\mathbf{\ddot{x}} + \frac{h^3}{6}\mathbf{\dddot{x}} + O(h^4) \\
                &=& \mathbf{x} + h\mathbf{f} + \frac{h^2}{2}\mathbf{f}'\mathbf{f} + \frac{h^3}{6}(\mathbf{f}''\mathbf{f}\,\mathbf{f} + \mathbf{f}'\mathbf{f}'\mathbf{f}) + O(h^4)
\end{array}$							(4)

Четвертый член суммы отличается, соответственно, имеет место ошибка, которая определяется вычитанием (3) из (4):
$$
\mathbf{\varepsilon} = \left(\frac{h^3}{6} - \frac{h^3\alpha}{4}\right)\mathbf{f}''\mathbf{f}\,\mathbf{f} + \frac{h^3}{6}(\mathbf{f}'\mathbf{f}'\mathbf{f})
$$
Итак, выбором $\alpha$ можно уменьшить значение ошибки, так как первый член суммы зависит от $\alpha$. Несложно увидеть, что при выборе $\alpha = 2/3$, то первый член суммы станет равен 0.

Метод с таким $\alpha$ называется методом Ралстона, его таблица Бутчера:
$$
\alpha = \frac{2}{3} : \  \begin{array}{|ccc}
     0 & \\
     2/3 & 0 \\
    \hline
     1/4 & 3/4
  \end{array}
$$
Ошибка метода Ралстона с учетом некоторых ограничений на функцию:
$$
||\mathbf{f}|| < M,\ ||\mathbf{f}'|| < L\ \Rightarrow\ \varepsilon < C h^3 ML^2,\quad C = \frac{1}{6}
$$

### Аналитические оценки ошибок методов Рунге-Кутты

Если $\exists M, L\ :\ \left\lVert\frac{\partial^i\mathbf{f}}{\partial \mathbf{x}^i}\right\rVert < \frac{L^i}{M^{i-1}}$, то как раз выполняются условия $||\mathbf{f}||<M, ||\mathbf{f}'||<L$. 

Вообще говоря, если найдены такие $M,L$, что данное неравенство выполняется, то для метода Рунге-Кутты порядка $p$:
$$
\varepsilon < C h^{p+1} M L^p
$$

#### Примеры

Возьмем классический метод Рунге-Кутты 4-го порядка с таблицей Бутчера:
$$
\begin{array}{|cccc}
     0 & \\
     1/2 & 0 \\ 
     0   & 1/2 & 0 \\
     0 & 0 & 1 & 0 \\ \hline
     1/6 & 1/3 & 1/3 & 1/6 \\
  \end{array}
$$
Известно теоретически рассчитанное значение константы $C$ для этого метода:
$$
C \approx 10.14 \times 10^{-2}
$$
Для метода 3/8 с таблицей Бутчера:
$$
\begin{array}{|cccc}
     0 & \\
     1/3 & 0 \\ 
     -1/3   & 1 & 0 \\
     1 & -1 & 1 & 0 \\ \hline
     1/8 & 3/8 & 3/8 & 1/8 \\
  \end{array}
$$

$$
C \approx 9.91 \times 10^{-2}
$$

Метод Ралстона 4-го порядка с таблицей Бутчера:
$$
\begin{array}{|cccc}     0 & \\     2/5 & 0 \\     \frac{-2889 + 1428 \sqrt{5}}{1024} & \frac{3875 - 1620 \sqrt{5}}{1024} & 0 \\      \frac{-3365 + 2094 \sqrt{5}}{6040} & \frac{-975 - 3046\sqrt{5}}{2552} & \frac{467040 + 203968\sqrt{5}}{240845} & 0 \\    \hline     \frac{263 + 24 \sqrt{5}}{1812} & \frac{125 - 1000 \sqrt{5}}{3828} & \frac{1024(3346 + 1623 \sqrt{5})}{5924787} & \frac{30 - 4\sqrt{5}}{123}  \end{array}
$$
Имеет минимально возможное для методов Рунге-Кутты значение $C$:
$$
C \approx 5.46 \times 10^{-2}
$$
Отметим, что данная оценка ошибки не использует реальные значения функции, поэтому настоящая ошибка может быть значительно меньше этой оценки. Метод, который оптимален с точки зрения константы $C$ может оказаться менее оптимальным на практике.

Попробуем оценивать ошибку, исходя из значений, рассчитанных по ходу работы метода.

### Вложенные методы Рунге-Кутты

Данные методы – некоторое расширение обычных методов Рунге-Кутты. Для их определения в таблицу Бутчера добавляется строка с другими коэффициентами $\hat{b}_i$:
$$
\begin{array}{|cccc}
    0     \\
    a_{21}     & 0 \\
     \vdots     & \vdots     &  \ddots   \\
     a_{s1}     & a_{s2}   &   \dots    & 0 \\
    \hline
     b_1        & b_2       &  \dots     & b_s\\
    \hline
     \hat{b}_1        & \hat{b}_2       &  \dots     & \hat{b}_s
  \end{array}
$$
Соответственно, $\mathbf{x}(t+h)$ вычисляется двумя способами:
$$
\mathbf{x}(t+h) = \mathbf{x}(t) + \sum_{i=1}^{s}b_i\mathbf{k}_i + \varepsilon, \ \ \varepsilon = O(h^{p+1}) \\

{\mathbf{x}}(t+h) = \mathbf{x}(t) + \sum_{i=1}^{s}\hat{b}_i\mathbf{k}_i + \hat\varepsilon,\ \ \hat\varepsilon = O(h^{\hat{p}+1})
$$
Таким образом, в методе совмещается два обычных метода. Как правило, при этом порядки $p, \hat{p}$ отличаются на 1.

Теперь можно рассчитать оценку ошибки, вычитая уравнения:
$$
\sum_{i=1}^{s}(\hat{b}_i - b_i)\mathbf{k}_i = \varepsilon - \hat\varepsilon = \varepsilon + O(h^{\hat p +1})
$$
Таким образом можно получать оценку той ошибки, которую мы хотим контролировать.

Для $p, \hat{p}$ метод называется вложенным методом порядка $p(\hat{p})$, где $p$ – порядок аппроксимации значения на следующем шаге, а $\hat{p}$ используется именно для оценки ошибки.

### Примеры

Метод Хойна-Эйлера 2(1). Число вычислений в правой части на каждом шаге $s=2$.
$$
\begin{array}{|ccc}
     0 & \\
     1 & 0 \\
    \hline
     1/2 & 1/2 \\
     \hline
     1 & 0
  \end{array}
$$
Метод Богацкого-Шампина 3(2), $s=4$.  FSAL (first same as last) – наличие у метода повторяющихся строк в таблице Бутчера позволяет использовать по 3 вызова правой части на шаг.
$$
\begin{array}{|cccc}
     0 & \\
     1/2 & 0 \\ 
     0   & 3/4 & 0 \\
     2/9 & 1/3 & 4/9 & 0 \\ \hline
     2/9 & 1/3 & 4/9 & 0 \\ \hline
     7/24 & 1/4 & 1/3 & 1/8 
  \end{array}
$$
Еще несколько вложенных методов:

* Метод Рунге-Кутты-Фельберга 4(5), $s=6$

* Метод Дормана-Принса 5(4), $s=7$, FSAL

### Подбор шага

Шаг можно не держать постоянным на всем промежутке интегрирования, а увеличивать его или уменьшать с тем, чтобы ошибка держалась в требуемых пределах.
$$
\begin{array}{lcl}
\mathbf{x}^{(n+1)} &=& \mathbf{x}(t) + \sum_{i=1}^{s}b_i\mathbf{k}_i \\
\hat{\mathbf{x}}^{(n+1)} &=& \mathbf{x}(t) + \sum_{i=1}^{s}\hat{b}_i\mathbf{k}_i 
\end{array}
$$
Оценка ошибки в этом случае может считаться так:
$$
\varepsilon = \hat{\mathbf{x}}^{(n+1)}  -  \mathbf{x}^{(n+1)} + O(h^{\hat p + 1})
$$
Задача: управлять шагом так, чтобы значение $\varepsilon$ не стало слишком большим.

Должно быть
$$
\left|\hat{x}^{(n+1)}_i  -  {x}^{(n+1)}_i\right| \leqslant \mathrm{tol}_i = \mathrm{Atol}_i + \max\left(\left|\hat{x}^{(n+1)}_i\right|,\left|{x}^{(n+1)}_i\right|\right)\cdot \mathrm{Rtol}_i
$$
Ошибка разделяется на две компоненты: абсолютную $\mathrm{Atol}_i$ и относительную (второй член суммы). Относительная ошибка умножается на максимальное значение из $|\hat{x}_i^{(n+1)}|, |x_i^{(n+1)}|$, так как может произойти так, что одно из значений станет равно 0.

Абсолютные и относительные допуски $\mathrm{Atol}_i и$ $\mathrm{Rtol}_i$ задаются пользователем, это пределы, в которых должна держаться ошибка.

Если оценка ошибки больше допустимого, можно, например, делить шаг пополам, а если наоборот слишком маленькая, то увеличивать. Такой способ не самый оптимальный.

Оптимальный выбор шага заключается в рассмотрении выражения:
$$
\mathrm{err} = \sqrt{\dfrac{1}{n} \sum_{i=1}^{n} \left( \dfrac{\hat{x}_i^{(n+1)} - x_i^{(n+1)}}{\mathrm{tol}_i} \right)^2} \sim h^{\min(p, \hat{p})}
$$
Данная величина асимптотически пропорциональная шагу в степени, наименьшей из $p, \hat{p}$. Пользуясь этим, можно подогнать $\mathrm{err}$ к 1. Для этого выбирается оптимальный шаг:
$$
h_\mathrm{opt} = h \left(\frac{1}{\mathrm{err}}\right)^{\frac{1}{\min(p, \hat p) + 1}}
$$
Таким образом, очередной шаг можно провести со значением оптимального шага, вновь посчитать ошибку, и велика вероятность, что она уже будет укладываться в заданные допуски.